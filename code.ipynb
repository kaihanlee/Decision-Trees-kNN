{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Dataset Analysis\n",
    "\n",
    "1. Import the **training set ONLY** using Pandas (**HINT**: the dataset is in csv format). We have given you the `feature_names` already below.\n",
    "\n",
    "2. Report the type of every feature (**HINT**: `DataFrame.dtype` might be handy).\n",
    "\n",
    "3. Report if the dataset is balanced.\n",
    "\n",
    "4. Print the feature values of every feature. In the case of a numerical feature print the range and average (with 3 decimal points) instead.\n",
    "\n",
    "5. Using plots of histograms, bar-graphs or heatmaps *briefly* comment on the following (don't forget to include the plots in your .ipynb notebook):\n",
    "    - Does the `age` feature follow a normal distribution (just by eyeballing)?\n",
    "    - Is the `poutcome` feature unimodal (just by eyeballing)?\n",
    "    - Is the `education` feature unimodal (just by eyeballing)?\n",
    "    - Taking into account **only** the numerical features do you notice any correlation between pairs of features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_names = [\"age\",\"job\",\"marital\",\"education\",\"default\",\"balance\",\"housing\",\n",
    "                              \"loan\",\"contact\",\"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\", \"category\"]\n",
    "\n",
    "# TODO: Fill-in (Answer questions 2)\n",
    "train = pd.read_csv('bank_train', index_col=False, sep=',', names=feature_names)   #read file\n",
    "\n",
    "# display all variable types exclusing 'category' as it is not a feature\n",
    "for i in range(len(feature_names[:-1])):\n",
    "    if feature_names[i] == 'day':   # 'day' is categorical\n",
    "        print(f'{feature_names[i]}: categorical')\n",
    "    elif train.dtypes[i] == 'int64':\n",
    "        print(f'{feature_names[i]}: numerical')\n",
    "    else: \n",
    "        print(f'{feature_names[i]}: categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train   # display train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['category'].value_counts(normalize=True)   # to check whether the dataset is balanced\n",
    "# Reference: https://dfrieds.com/data-analysis/value-counts-python-pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Fill-in (Answer question 3)\n",
    "for i in range(len(feature_names[:-1])):\n",
    "    if feature_names[i] == 'day': \n",
    "        print('{}: number={}, {}'.format(feature_names[i], len(set(train[feature_names[i]])), \n",
    "                                         list(set(train[feature_names[i]]))))\n",
    "    elif train.dtypes[i] == 'int64':   # if variable is numeric, then display range and average\n",
    "        print('{}: min={}, max={}, avg={:0.3f}'.format(feature_names[i], min(set(train[feature_names[i]])), \n",
    "                        max(set(train[feature_names[i]])), train[feature_names[i]].mean()))\n",
    "    else:    # if variable is string, then display all feature values\n",
    "        print('{}: number={}, {}'.format(feature_names[i], len(set(train[feature_names[i]])), \n",
    "                                         list(set(train[feature_names[i]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#TODO Fill-in (Answer question 4)\n",
    "# plot histograms\n",
    "train['age'].hist()\n",
    "plt.show()\n",
    "train['poutcome'].hist()\n",
    "plt.show()\n",
    "train['education'].hist()\n",
    "plt.show()\n",
    "\n",
    "fhm = train.select_dtypes(exclude=['object'])   # drop non-numeric variables\n",
    "fhm = fhm.drop('day',axis=1)   # drop 'day' feature\n",
    "corr = fhm.corr()   # calculate correlations\n",
    "sns.heatmap(corr, annot = True)   # plot heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II (Decision Trees)\n",
    "\n",
    "- Load data without any preprocessing\n",
    "- Perform hyperparameter tuning on depth of DT\n",
    "- Plot train, dev accuracy curves\n",
    "- Test on test set ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "from BankDataset import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = load_dataset('bank_train', preprocess_onehot=True)\n",
    "dev_dataset = load_dataset('bank_dev', preprocess_onehot=True)\n",
    "test_dataset = load_dataset('bank_test', preprocess_onehot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display object attributes\n",
    "for attr, value in train_dataset.__dict__.items():\n",
    "        print(attr, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill-in (Hyperparameter Tuning)\n",
    "max_depth = range(1, 30)   # set suitable max depth range\n",
    "accuracy_train = []   # create empty list for training accuracy\n",
    "\n",
    "# loop accuracy for different max depth\n",
    "for i in max_depth:\n",
    "        BankTree = DecisionTreeClassifier(criterion=\"gini\", max_depth = i)\n",
    "        BankTree.fit(train_dataset.X, train_dataset.y)   # fit training dataset\n",
    "        \n",
    "        pred_train = BankTree.predict(train_dataset.X)   # predict category with trained model\n",
    "        \n",
    "        accuracy_train.append(metrics.accuracy_score(train_dataset.y, pred_train))   # add accuracy to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dev = []   # create empty list for development accuracy\n",
    "\n",
    "# loop accuracy for different max depth\n",
    "for i in max_depth:\n",
    "        BankTree = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth = i)\n",
    "        BankTree.fit(train_dataset.X, train_dataset.y)   # fit development dataset\n",
    "        \n",
    "        pred_dev = BankTree.predict(dev_dataset.X)   # predict category with trained model\n",
    "        \n",
    "        accuracy_dev.append(metrics.accuracy_score(dev_dataset.y, pred_dev))   # add accuracy to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth, accuracy_train, label=\"Train\")   # plot training accuracy curve\n",
    "plt.plot(max_depth, accuracy_dev, label=\"Dev\")   # plot development accuracy curve\n",
    "\n",
    "# add legend, title, axis labels, and save the plot\n",
    "plt.legend(bbox_to_anchor=(0.8, 0.3), loc='upper left', borderaxespad=0.)\n",
    "plt.title('Accuracy against Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Q2a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get depth with the maximum accuracy\n",
    "print(\"The maximum accuracy is {:1.3f} at max_depth = {}\".format(max(accuracy_dev), accuracy_dev.index(max(accuracy_dev))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill-in (Test on test set)   \n",
    "BankTree = DecisionTreeClassifier(criterion=\"gini\", max_depth = accuracy_dev.index(max(accuracy_dev))+1)\n",
    "BankTree.fit(train_dataset.X, train_dataset.y)\n",
    "\n",
    "# predict with test set\n",
    "pred_test = BankTree.predict(test_dataset.X)\n",
    "print(\"DecisionTrees's Accuracy (Test Set): \", metrics.accuracy_score(test_dataset.y, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III (k Nearest Neighbours)\n",
    "\n",
    "- Load data with 1-hot encoding and scaling\n",
    "- Perform hyperparameter tuning on number of neighbours k\n",
    "- Plot train, dev accuracy curves\n",
    "- Test on test set ONCE...more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading (load data again! Careful with preprocessing parameters)\n",
    "from BankDataset import load_dataset\n",
    "\n",
    "# TODO: Fill-in\n",
    "train_dataset = load_dataset('bank_train', preprocess_onehot=True, apply_scaling=True)\n",
    "dev_dataset = load_dataset('bank_dev', preprocess_onehot=True, apply_scaling=True)\n",
    "test_dataset = load_dataset('bank_test', preprocess_onehot=True, apply_scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display object attributes\n",
    "for attr, value in train_dataset.__dict__.items():\n",
    "        print(attr, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Fill-in (Hyperparameter Tuning)\n",
    "\n",
    "n_neighbors = range(1,30,2)   # set suitable nearest neighbors range taking odd values only\n",
    "accuracy_train = []   # create empty list for training accuracy\n",
    "\n",
    "# loop accuracy for different number of nearest neighbors\n",
    "for i in n_neighbors:\n",
    "        BankTree = KNeighborsClassifier(n_neighbors=i)\n",
    "        BankTree.fit(train_dataset.X, train_dataset.y)   # fit training dataset\n",
    "        \n",
    "        pred_train = BankTree.predict(train_dataset.X)   # predict category with trained model\n",
    "        \n",
    "        accuracy_train.append(metrics.accuracy_score(train_dataset.y, pred_train))   # add accuracy to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dev = []   # create empty list for development accuracy\n",
    "\n",
    "# loop accuracy for different number of nearest neighbors\n",
    "for i in n_neighbors:\n",
    "        BankTree = KNeighborsClassifier(n_neighbors=i)\n",
    "        BankTree.fit(train_dataset.X, train_dataset.y)   # fit development dataset\n",
    "        \n",
    "        pred_dev = BankTree.predict(dev_dataset.X)   # predict category with trained model\n",
    "        \n",
    "        accuracy_dev.append(metrics.accuracy_score(dev_dataset.y, pred_dev))   # add accuracy to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_neighbors, accuracy_train, label=\"Train\")   # plot training accuracy curve\n",
    "plt.plot(n_neighbors, accuracy_dev, label=\"Dev\")   # plot development accuracy curve\n",
    "\n",
    "# add legend, title, axis labels, and save the plot\n",
    "plt.legend(bbox_to_anchor=(0.8, 0.8), loc='upper left', borderaxespad=0.)\n",
    "plt.title('Accuracy against K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Q3a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimum k value where validation accuracy is smaller than training accuracy\n",
    "difference = []\n",
    "zip_object = zip(accuracy_dev, accuracy_train)\n",
    "\n",
    "for accuracy_dev_i, accuracy_train_i in zip_object:\n",
    "    difference.append(accuracy_dev_i-accuracy_train_i)\n",
    "\n",
    "ind = next(x for x, val in enumerate(difference) if val > 0)\n",
    "max(accuracy_dev[:ind])   # get max accuracy of corresponding k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get global maximum of validation accuracy\n",
    "print(\"The maximum accuracy of development set is {:1.4f} at k={}. \".format(max(accuracy_dev[:ind]), \n",
    "                                                    n_neighbors[accuracy_dev.index(max(accuracy_dev[:ind]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill-in (Test on test set)\n",
    "BankTree = KNeighborsClassifier(n_neighbors=(n_neighbors[accuracy_dev.index(max(accuracy_dev[:ind]))]))\n",
    "BankTree.fit(train_dataset.X, train_dataset.y)\n",
    "\n",
    "# predict with test set\n",
    "pred_test = BankTree.predict(test_dataset.X)\n",
    "print(\"DecisionTrees's Accuracy (Test Set): \", metrics.accuracy_score(test_dataset.y, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
